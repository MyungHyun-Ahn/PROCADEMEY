# 캐시 메모리
### CPU 캐시 구조
CPU에는 L1, L2, L3 캐시가 있다.
* L1, L2, L3 순서로 Core와 가깝다.
* intel 프로세서 기준 L1, L2 캐시가 코어마다 있고 L3 캐시는 공유하는 구조

![12-01](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/4480c500-c3c4-4dc7-afd4-23f251fecb8a)

### 구조체 패딩을 왜 하는가?
캐시 메모리는 근접한 메모리에서 데이터를 긁어오기 때문

근접한 메모리의 기준
* 64 바이트
  * 최근의 CPU는 모두 64바이트 크기
* 캐시는 한번에 64바이트 크기의 캐시라인 만큼 긁어온다.

여기서 구조체 패딩을 하는 이유
* 한 번에 데이터를 가져오기 위함
* 성능이 중요한 부분에서는 캐시 구조까지 고려하여 변수를 배치

같은 캐시 라인에 변수를 두는 방법
* 변수들을 구조체로 묶고 구조체의 시작 주소를 64바이트의 경계에 세우면 같은 캐시 라인에 존재하게 됨

```C++
alignas(64) // 시작 주소를 64바이트 경계로 맞춤
struct ST
{
    int a;
    int b;
};
```

문제가 생기는 경우
  * 데이터가 캐시 라인에 걸쳤을 때 발생

특정 주소 값의 캐시 라인 시작 지점을 알고 싶다면
* 0xfffffc0으로 & 비트 and 마스킹
* 하위 6비트를 날리는 것

캐시 히트율을 높이는 방법
* 지역 변수를 활용하면 보통 히트율이 높다.
* 가장 좋은 것은 변수들이 모두 함수의 스택 프레임 안에 있는 것
* 구조체 경계 자체를 바꾸면 된다. - alignas로 바꿀 수 있음
  * 메모리 낭비는 있을 수 있다.
  * 캐시 메모리 또한 낭비될 수 있다.
* 반대로 전역 변수를 사용하면 캐시 미스 확률이 증가
  * 메모리 위치가 멀기 때문
  * 따라서 명확한 이유가 아니라면 전역 변수는 지양

### non 캐시 메모리
DMA (Direct Memory Access)
* CPU 캐시를 거쳐서 오지만 캐시에 저장하지는 않는다.
* 우리가 일반적으로 사용하는 메모리는 아니다.
  * io 장치나 그래픽 드라이버 등이 사용

### 캐시 무효화
캐시 라인의 내용이 변경되면 무효화가 발생
* 해당 캐시 라인은 더이상 쓸 수 없게 됨
* 다음 접근에서는 무조건 캐시 미스


## MESI 캐시 프로토콜
이전 정리했던 내용 긁어옴

## MSI 스누핑 프로토콜
MSU 스누핑(snooping) 프로토콜
* 캐시 코히런스의 가장 고전적인 해법 중 하나
* 캐시 라인 마다 세 가지 코히런스 MSI 상태를 가질 수 있도록 한다.
* 캐시에 접근할 때마다 모든 캐시에게 버스(bus)를 통해 신호를 보내는 스누핑 작업을 한다.

MSI 상태 세 가지
1. Invalid : 어떤 캐시 라인의 상태가 유효하지 않다.
   * 읽거나 쓰려면 반드시 값을 요청해야 한다.
2. Shared : 캐시 라인이 한 곳 이상에서 공유 중이다. 또는 자기 자신만 들고 있다.
   * 그러나 이 캐시 라인은 dirty 하지 않다.
   * 즉, 읽기만 한 상태
   * 메모리도 캐시 라인의 최신 값을 가지고 있다.
   * 어떤 프로세서가 쓰기를 하려면 반드시 신호를 보내 자신의 캐시 라인을 M 상태로 바꾸면서 다른 캐시 사본은 I로 바꿔야 한다.
3. Modified : 캐시 라인이 어떤 한 프로세서에 의해 고쳐졌음(dirty)를 뜩한다.
   * 메모리에는 이 값이 반영되지 않았을 수도 있다.
   * 캐시 라인이 M 상태라면 오직 하나의 코어만 이 캐시 라인을 가지고 있다.

## MESI 프로토콜
MSI 프로토콜에 추가적인 최적화로 버스에 신호를 보내는 횟수와 메모리 접근 횟수를 줄여보자.
* 프로세서 개수가 많아지면 버스 스누핑 트래픽도 증가해 병목 지점이 된다.
* MSI 프로토콜의 가장 큰 단점은 아무도 데이터를 공유하지 않아도 버스 트래픽이 낭비되는 점
* MESI 프로토콜은 이것을 해결한다.

MESI 프로토콜
* MSI 프로토콜에서 E(Exclusive) 상태를 추가한다.
* MSI에서 캐시 라인은 오직 자신만이 클린 상태이어도 S, 공유된 상태가 되어야 했다.
* S 상태에서 혼자만 깨끗한 데이터를 가지고 있는 상태를 E라고 한다.
* S 상태는 이제 반드시 두 개 이상의 캐시가 사본을 가지고 있는 경우가 된다.

## 캐시 메모리 쓰기 정책
## 캐시의 쓰기 정책
캐시에 데이터를 쓸 때 두 가지 정책
1. 라이트 쓰루(write-through) : 캐시 쓰기가 있을 때, 메모리 또는 아래 계층의 캐시로 바로 반영
   * 캐시를 쓸 때마다 아래 계층의 캐시나 메모리에 반영해야 하므로 레이턴시가 길다.
2. 라이트 백(write-back) : 변경된 데이터를 일단 캐시가 들고 있다가 나중에 캐시에서 쫓겨날 때 메모리를 갱신
   * 구현이 라이트 쓰루에 비해 복잡하다.
   * 캐시 라인마다 더티 비트(diry bit)를 둔다.
   * 이 값은 0으로 초기화되고 후에 쓰여지면 더티 비트를 켠다.
   * 갱신된 데이터가 캐시에만 있고 아직 메모리에는 반영되지 않았음을 의미
   * 캐시 라인이 교체되면 메모리에 바뀐 값을 쓴다.

대부분의 캐시는 라이트 백 쓰기 정책
* 예외적으로 L1 명령어 캐시는 라이트 쓰루
* 명령어 코드는 거의 수정이 일어나지 않기 때문
* Self-modifying code(SMC) : 자기 자신의 명령어를 고치는 프로그램, 컴퓨터 바이러스와 익스플로잇이 이 구조를 띠기도 한다.

캐시 쓰기 정책은 운영체제나 파일 입출력 프로그래밍에서도 쉽게 찾아볼 수 있다.
* 일반적인 하드디스크는 쓰기 캐시, 라이트 백 정책의 쓰기 캐시가 켜져있다.
* 하드 디스크에 바로 쓰지 않고 쓰기 캐시를 두고 데이터가 모이면 주기적으로 이 내용을 디스크로 보낸다.
* USB 처럼 빈번히 탈착되는 저장장치에 나쁘다.
  * 반드시 뽑을 때 안전한 하드웨어 제거를 거쳐야 한다.
  * 그래서 USB 메모리는 기본적으로 쓰기 캐시를 쓰지 않도록 설정된다.

### 간단하게 정리하면
Write through : 변경 즉시 적용

Write Back : 일단 변경은 캐시에만 - M(Modified) 표시만
* 일반적으로 많이 사용하는 정책
* 캐시 값이 수정되면 L3까지 Modified 표시를 하고 캐시를 비워질 때 메인 메모리에 적용

L1 -> L2 -> L3 순서로 메모리에서 빠져나가야 한다.
* RAM에 쓰면 M -> S 상태가 된다.

### CPU 사용률
CPU 사용률이 50%라는 것
* 일정 시간에 스레드가 50% 간 붙어 있다.
* 스레드 전환 시간도 사용률에 들어간다.
* 그냥 돌릴 스레드가 없어서 못돌린 것
* io가 진행될 때 코어 소유권을 내려놓는다.
* 사용률은 낮추고 처리율을 높이는 것이 좋은 것

### 보통 L1 캐시를 쪼개서 사용한다.
Data 캐시와 Inst 캐시
* 데이터 영역과 코드 영역을 나눈다.
* 데이터 캐시로만 캐시 미스를 계산한다.
* L2, L3는 구분 안하고 남겨만 둔다.

### 캐시 설계
실제 L1 캐시 크기 : 32K
* Tag, Index, Offset
* 캐시 구성 요소, 용량 포함 X
* 512개 캐시 라인 저장 가능

32비트 x86 기준 주소는 4바이트
* Offset : 하위 6bit 캐시라인 크기만큼
* Index : 9 bit
* Tag : 나머지

64비트에서도 똑같다. - Tag가 커질 뿐

캐시라인[512] 배열이 나온다.
* 그런데 보통 주변의 공간을 사용하므로
* 9bit Index 에선 32K 씩 건너뛰면 캐시 미스가 극대화됨
  * 인덱스가 같아지기 때문

따라서 위의 비트를 활용한다.
* n-way, 2-way, 4-way ...

만약 8-way면 512 / 8
* Index 비트를 8(3bit) 만큼 적게 활용
* Tag -> 20 bit
* Index -> 6 bit
* offset -> 6 bit

캐시 구현에 사용할 주소를 어떤 것을 사용할 것인가?
* 물리 주소
  * 변동 가능
  * 예측 불가
  * 지역적 공간성 고민한 것이 무의미
* 가상 주소
  * 다른 프로세스와 태그가 겹칠 가능성 있음
  * PID도 함께 저장하지 않으면 
* 가상 주소 + 물리 주소
  * 가상 주소의 Index, 물리 주소의 Tag 사용
  * 페이지 -> 4KB 단위로 매핑
  * 가상 주소와 물리 주소의 4K 범위는 같다.
  * 페이지 내에서의 오프셋(4kb) -> 12비트 (index + offset)으로 활용

### 캐시 히트율을 높이려면
* 지역적 공간성
* 시간적 공간성
* 순차 접근하기
* 읽고, 쓰기 캐시라인 분리하기
  * 캐시 무효화 줄이기 / return 빈번할 때
* 변화가 적은 변수, 많은 변수 끼리 캐시 라인을 분리
  * 로직 단위로
* 함수 안에서 쓰는 메모리가 캐시 히트가 나오도록 멤버 변수의 위치를 둘 수 있다.
  * but 다른 함수에서 성능이 낮아질 수 있음을 고려
* CPU 선호도를 설정하면 오히려 성능이 떨어질 수 있다.
  * 코어가 남아돌 때 고려해볼만 함

### 캐시에 대한 더 자세한 정리
[캐시 정리](https://github.com/MyungHyun-Ahn/SystemProgramming/blob/main/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EA%B0%80_%EB%AA%B0%EB%9E%90%EB%8D%98_%EB%A9%80%ED%8B%B0%EC%BD%94%EC%96%B4_CPU_%EC%9D%B4%EC%95%BC%EA%B8%B0/12_%EA%B3%A0%EC%84%B1%EB%8A%A5_%ED%94%84%EB%A1%9C%EC%84%B8%EC%84%9C%EC%9D%98_%ED%95%84%EC%88%98_%EC%A1%B0%EA%B1%B4_%EB%98%91%EB%98%91%ED%95%9C_%EC%BA%90%EC%8B%9C/12.md)

### 캐시 히트 시뮬레이터 구현

수업 내용 기반 + 위 캐시 정리를 참고하여 구현
```C++
#pragma once

constexpr int CACHE_SIZE = 512;
constexpr int CACHE_WAY = 8;
constexpr int CACHE_WAY_BIT = 3;

// L1 캐시 시뮬레이터
// L1 캐시 크기 32KB
// Index 9 - WAY_BIT, offset 6 : tag 나머지

__forceinline DWORD GetCacheIndex(UINT_PTR addr)
{
	return ((addr >> 6) & 0x3F);
}

__forceinline UINT_PTR GetCacheTag(UINT_PTR addr)
{
	UINT_PTR TAG_MASK = 0xFFF;
	return (addr & ~TAG_MASK);
}

struct CacheLine
{
public:
	CacheLine() = default;

	CacheLine(void *ptr)
	{
#ifdef _WIN64
		offset = (unsigned __int64)ptr & 0x3F;
		index = ((unsigned __int64)ptr >> 6) & 0x3F;
		tag = (unsigned __int64)ptr >> 12;
#else
		offset = (unsigned int)ptr & 0x3F;
		index = ((unsigned int)ptr >> 6) & 0x3F;
		tag = (unsigned int)ptr >> 12;
#endif
	}


#ifdef _WIN64
	unsigned __int64 offset;
	unsigned __int64 index;
	unsigned __int64 tag;
#else
	unsigned int offset;
	unsigned int index;
	unsigned int tag;
#endif
};

class CacheSimulator
{
public:
	CacheSimulator()
	{

	}

	bool IsCacheHit(void *ptr)
	{
		CacheLine cl(ptr);

		// 먼저 캐시에 있는지 찾는다.
		int accessIndex = -1;
		for (size_t i = 0; i < 8; i++)
		{
			if (m_arrCacheL1[cl.index * CACHE_WAY + i].tag == cl.tag)
			{
				accessIndex = i;
			}
		}

		// 캐시 히트
		if (accessIndex != -1)
		{
			CacheAccess(accessIndex, cl.index);
			return true;
		}
		// 캐시 미스
		// 교체 정책 수행
		
		accessIndex = CacheExchange(cl.index);
		m_arrCacheL1[accessIndex - CACHE_WAY + cl.index * CACHE_WAY] = cl;

		return false;
	}

	__forceinline void CacheAccess(int accessIndex, int index)
	{
		unsigned char route = m_arrCacheRoute[index];
		unsigned char indexBit = 0b10000000; // 이것으로 인덱스 판단

		// accessIndex로 가는 접근 경로 기록
		accessIndex += CACHE_WAY;

		// accessIndex % 2 == 0 왼쪽, 1 오른쪽
		for (int i = 0; i < CACHE_WAY_BIT; i++)
		{
			bool isRight = true;
			if (accessIndex % 2 == 0)
			{
				isRight = false;
			}

			accessIndex = accessIndex << 1;

			unsigned char curIndex = indexBit >> accessIndex;
			if (isRight)
				route |= curIndex;
			else
				route &= ~curIndex;
		}

		m_arrCacheRoute[index] = route;
	}

	__forceinline int CacheExchange(int index)
	{
		unsigned char route = m_arrCacheRoute[index];
		unsigned char indexBit = 0b10000000; // 이것으로 인덱스 판단

		int accessIndex = 1;
		for (int i = 0; i < CACHE_WAY_BIT; i++)
		{
			unsigned char curIndex = indexBit >> accessIndex;

			// 왼쪽
			if ((route & curIndex) == curIndex)
			{
				route &= ~curIndex; // 접근 기록
				accessIndex = accessIndex << 1;
			}
			else // 오른쪽
			{
				route |= curIndex; // 접근 기록
				accessIndex = (accessIndex << 1) + 1;
			}
		}

		m_arrCacheRoute[index] = route;
		return accessIndex;
	}

private:
	CacheLine m_arrCacheL1[CACHE_SIZE];

	// 경로 기록용
	unsigned char m_arrCacheRoute[CACHE_SIZE / CACHE_WAY] = { 0, };
};
```